#!/usr/bin/python

import socket
import sys
from urlparse import urlparse
from http import *


#import requests
#from lxml import html

USERNAME = "1778409"
PASSWORD = "ZUE3UDQE"

fakebook_url = urlparse('http://fring.ccs.neu.edu/fakebook/')
login_url = urlparse('http://fring.ccs.neu.edu/accounts/login/?next=/fakebook/')
full_login_path = "/accounts/login/?next=/fakebook/"
HOST = fakebook_url.netloc 
# fakebook_url.netloc fring.ccs.neu.edu
FAKEBOOK_PATH = fakebook_url.path
LOGIN_PATH = login_url.path
HTTP_VERSION = "HTTP/1.1"

PORT = 80
HOST_PORT = (HOST, PORT)

urls_visited = []
urls_tovisit = []
secret_flags = []

csrf = 0
session_id = 0

# create the socket
try:
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
except socket.error as e:
    print 'ERROR: Failed to create socket!'
    exit(1)



class PageParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.secret_flag_found = False

    def handle_starttag(self, tag, attrs):
        global urls_visited, urls_tovisit, secret_flags
        # find links in the page
        if tag == 'a':
            for attr, val in attrs:
                if attr == 'href':
                    # only add to tovisit list if the url has not been visited
                    # doesn't exist in tovisit list already, and it's valid
                    val_path = url_parse(val).path
                    if val_path not in urls_visited and val_path not in urls_tovisit and "fring.ccs.neu.edu" in val:
                        urls_tovisit.append(val_path)
                        print("add a new valid url to visit: %s" % val_path)
        # find secret flag
        if tag == 'h2':
            for attr, val in attrs:
                if attr == 'class' and val == 'secret_flag':
                    self.secret_flag_found = True


    def handle_endtag(self, tag):
        global urls_visited, urls_tovisit
        #print("end tag: " + str(tag))
        if tag == "html":
            # remove the url from tovisit list

            # add to visited list
            #urls_tovisit.remove()
            pass

    def handle_data(self, data):
        global urls_visited, urls_tovisit, secret_flags, csrf, session_id
        #print("Data: " + data)
        if "csrftoken" in data:
            csrf = data.split("csrftoken=")[1].split(";")[0]

        if "sessionid" in data:
            session_id = data.split("sessionid=")[1].split(";")[0]

        if self.secret_flag_found:
            flag = data.split(" ")[1]
            print "!!!!!!!!!!!!!!!!!!!!!!!!!!!!maybe this is the flag: " + str(flag)
            if flag not in secret_flags:
                secret_flags.append(flag)
                self.secret_flag_found = False
                print "Yay!!! Found one secret flag %s" % str(flag)

            


"""
    HTTP GET request
"""
def http_GET(path):
    global HOST_PORT, HOST, HTTP_VERSION
    request = Request("GET", path, HTTP_VERSION, HOST)
    # get request
    print '==========================GET Request======================'
    print(request.get_request())
    sock.sendall(request.get_request())
    response = sock.recv(9000)
    (status_code, resp) = handle_http_status_code(path)
    return (status_code, resp)

"""
    HTTP GET request with the cookie
"""
def http_GET_with_cookie(path):
    global session_id, csrf, HOST_PORT, HOST, HTTP_VERSION
    request = Request("GET", path, HTTP_VERSION, HOST, token=csrf, session_id=session_id)
    print '==========================GET Request======================'
    print(request.get_request_with_cookie())
    sock.sendall(request.get_request_with_cookie())
    response = sock.recv(9000)
    (status_code, resp) = handle_http_status_code(path)
    return (status_code, resp)

"""
    HTTP POST request
"""
def http_POST(path, data):
    global HOST_PORT, HTTP_VERSION, HOST, session_id, csrf
    request = Request("POST", path, HTTP_VERSION, HOST, data, csrf, session_id)
    print '==========================POST Request======================'
    print(request.post_request())
    sock.sendall(request.post_request())
    response = sock.recv(9000)
    (status_code, resp) = handle_http_status_code(path)
    return (status_code, resp)


"""
Logging in to fakebook, HTTP POST
1. initial GET request
2. POST with csrf tocken and sessionid
3. get new session id
4. GET with new session id
"""
def login():
    global LOGIN_PATH, HOST, USERNAME, PASSWORD, HOST_PORT, full_login_path, csrf, session_id
    # connect to the socket
    sock.connect(HOST_PORT)
    (get_status, get_response) = http_GET(full_login_path)
    print '---------------------------GET Response---------------------'
    print(str(get_response))
    while get_status == '200':

        crawl_webpage(get_response)
    else:
        print"First GET failed, exit the program"
        sys.exit(1)

    # create POST request to login
    data = "username=%s&password=%s&csrfmiddlewaretoken=%s&next=%%2Ffakebook%%2F" % (USERNAME, PASSWORD, csrf)
    post_response = http_POST(LOGIN_PATH, data)
    print('-------------------------POST Response---------------------------------')
    print(str(post_response))
    
    # renew session id
    crawl_webpage(post_response)
    print("new session id = " + str(session_id))
    handle_http_status_codes(post_response, LOGIN_PATH)
    # new_session_id = parser.feed(post_response).sessionid

    # #sock.setblocking(0)

    # GET with cookie
    # handle_http_status_codes(response, full_login_path)

# read through xml and find flags, find hyperlinks, and recurse get

"""
    handle returned status codes
    200 - accepted
    301 - moved permanently. try the request again using the new URL given by the server in the Location header.
    403 - Forbidden
    404 - Not Found 
     Our web server may return these codes in order to trip up your crawler.
     In this case, your crawler should abandon the URL that generated the error code.
    500 - Internal Server Error
     Our web server may randomly return this error code to your crawler.
     In this case, your crawler should re-try the request for the URL until the request is successful.
"""

def handle_http_status_codes(response, path):
    global urls_visited, urls_tovisit
    status_code = response.split(' ')[1]
    if status_code == '200':
         # good
         return (status_code, response)
    if status_code == '302':
        new_url = response.split('Location: ')[1].split('\n')[0]
        new_url_path = urlparse(new_url).path
        print("new path from POST" + str(new_url_path))
        if session_id == 0:
            new_response = http_GET(new_url_path)
        else:
            # make get (cookie) request again
            new_response = http_GET_with_cookie(new_url_path)
        print "----------------------new GET response from 302------------------"
        print new_response        
        # remove url path from tovisit, add to visited
        if new_url_path in urls_tovisit:
            urls_tovisit.remove(new_url_path)
        if new_url_path not in urls_visited:
            urls_visited.append(new_url_path)
        #return (status_code, new_response)
    if status_code == '403' or status_code == '404':
        # abondon url path
        # remove url from tovisit, add to visited
        if path in urls_tovisit:
            urls_tovisit.remove(path)
        if path not in urls_visited:
            urls_visited.append(path)
        return (status_code, response)
    if status_code == '500':
        if session_id == 0:
            new_response = http_GET(path)
        else:
            # make get (cookie) request again
            new_response = http_GET_with_cookie(path)
            


"""
crawls the webpage: find new links to visit and find flags
"""
def crawl_webpage(response):
    parser = PageParser()
    parser.feed(response)
    # csrf token and session id should be updated
    print '==========================token and session======================'
    print csrf
    print session_id






"""
# a list of sites that are visited
# a list of sites to be visited
# only craw the pages that are valid, starts with fring.ccs.neu.edu

# loggin:
    # 
# Request class / Reponse class
# implement HTTP/1.1:
    # contains host in the header
# HTTP requests:
    # GET
    # POST
    # COOKIE MANAGEMENT
# HTTP Response:
    # 301
    # 403
    # 404
    # 500
# Interpret the responded html, and find flgas
"""
def main():
    
    login()
    #login_requests()

if __name__ == "__main__":
    main()


