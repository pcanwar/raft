#!/usr/bin/python

import socket
import sys
from HTMLParser import HTMLParser
from urlparse import urlparse

import time

USERNAME = "1778409"
PASSWORD = "ZUE3UDQE"

fakebook_url = urlparse('http://fring.ccs.neu.edu/fakebook/')
login_url = urlparse('http://fring.ccs.neu.edu/accounts/login/?next=/fakebook/')
full_login_path = "/accounts/login/?next=/fakebook/"
HOST = fakebook_url.netloc 
# fakebook_url.netloc fring.ccs.neu.edu
FAKEBOOK_PATH = fakebook_url.path
LOGIN_PATH = login_url.path
HTTP_VERSION = "HTTP/1.1"

PORT = 80
HOST_PORT = (HOST, PORT)

paths_visited = []
paths_tovisit = []
secret_flags = []

csrf = ''
session_id = ''



class PageParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.secret_flag_found = False

    def handle_starttag(self, tag, attrs):
        global paths_visited, paths_tovisit, secret_flags
        # find links in the page
        if tag == 'a':
            for attr, val in attrs:
                if attr == 'href':
                    # only add to tovisit list if the url has not been visited
                    # doesn't exist in tovisit list already, and it's valid
                    val_path = urlparse(val).path
                    if val_path not in paths_visited and val_path not in paths_tovisit and "fring.ccs.neu.edu" in val:
                        paths_tovisit.append(val_path)
                        print("add a new valid url to visit: %s" % val_path)
        # find secret flag
        if tag == 'h2':
            for attr, val in attrs:
                if attr == 'class' and val == 'secret_flag':
                    self.secret_flag_found = True


    def handle_endtag(self, tag):
        global paths_visited, paths_tovisit
        if tag == "html":
            # TODO
            # remove the url from tovisit list
            # if new_url_path in urls_tovisit:
            #     urls_tovisit.remove(new_url_path)
            # if new_url_path not in urls_visited:
            #     urls_visited.append(new_url_path)
            # add to visited list
            #urls_tovisit.remove()
            pass

    def handle_data(self, data):
        global paths_visited, paths_tovisit, secret_flags, csrf, session_id
        #print("Data: " + data)
        if "csrftoken" in data:
            csrf = data.split("csrftoken=")[1].split(";")[0]

        if "sessionid" in data:
            session_id = data.split("sessionid=")[1].split(";")[0]

        if self.secret_flag_found:
            flag = data.split(" ")[1]
            print "!!!!!!!!!!!!!!!!!!!!!!!!!!!!maybe this is the flag: " + str(flag)
            # TODO check flag length
            if flag not in secret_flags:
                secret_flags.append(flag)
                self.secret_flag_found = False
                print "Yay!!! Found one secret flag %s" % str(flag)


parser = PageParser()


"""
receive HTTP responses using the socket
"""
def recv_response(sock):
    full_response = ''
    full_response += sock.recv(9000)
    while '</html>' not in full_response:
        resp = sock.recv(9000)
        if resp:
            full_response += resp
        else:
            break

    sock.close()
    return full_response




"""
    handle returned status codes
    200 - accepted
    301 - moved permanently. try the request again using the new URL given by the server in the Location header.
    403 - Forbidden
    404 - Not Found 
     Our web server may return these codes in order to trip up your crawler.
     In this case, your crawler should abandon the URL that generated the error code.
    500 - Internal Server Error
     Our web server may randomly return this error code to your crawler.
     In this case, your crawler should re-try the request for the URL until the request is successful.
"""

def handle_http_status_codes(response, path):
    global paths_visited, paths_tovisit
    print("int handle: path(" + path)

    status_code = response.split(' ')[1]
    if status_code == '200':
         return (status_code, response)

    if status_code == '302':
        new_url = response.split('Location: ')[1].split('\n')[0]
        new_url_path = urlparse(new_url).path
        print("new path from POST" + str(new_url_path))
        # remove url path from tovisit, add to visited
        if new_url_path in paths_tovisit:
            paths_tovisit.remove(new_url_path)
        if new_url_path not in paths_visited:
            paths_visited.append(new_url_path)
        # redirect GET to the new url path
        if session_id == '':
            new_response = http_GET(new_url_path)
        else:
            # make get (cookie) request again
            new_response = http_GET_with_cookie(new_url_path)
        print "----------------------new GET response from 302------------------"
        print new_response  # TODO if delete this then no welcome page, why

    if status_code == '403' or status_code == '404':
        # abondon url path
        # remove url from tovisit, add to visited
        if path in paths_tovisit:
            paths_tovisit.remove(path)
        if path not in paths_visited:
            paths_visited.append(path)
        return (status_code, response)

    if status_code == '500':
        if session_id == '':
            http_GET(path)
        else:
            # make get (cookie) request again
            http_GET_with_cookie(path)



"""
    HTTP GET request
"""
def http_GET(path):
    global HOST_PORT, HOST, HTTP_VERSION
    # construct GET request
    request_as_str = "GET %s %s\nHost: %s\n\n" % (path, HTTP_VERSION, HOST)
    print('==========================GET Request======================')
    print(request_as_str)
    # send GET request
    # create the socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request_as_str)
        # get response
        response = recv_response(sock)
        #(status_code, resp) = handle_http_status_codes(response, path)
        return response #(status_code, resp)

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)


"""
    HTTP GET request with the cookie
"""
def http_GET_with_cookie(path):
    global session_id, csrf, HOST_PORT, HOST, HTTP_VERSION
    request_as_str = '''\
GET %s %s
Host: %s
Cookie: csrftoken=%s; sessionid=%s

''' % (path, HTTP_VERSION, HOST, csrf, session_id)
    print '==========================GET Request with cookie======================'
    print("path: " + path)
    print(request_as_str)
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request_as_str)
        response = recv_response(sock)
        #(status_code, resp) = handle_http_status_codes(response, path)
        return response #(status_code, resp)

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)


"""
    HTTP POST request
"""
def http_POST(path, data):
    global HOST_PORT, HTTP_VERSION, HOST, session_id, csrf
    request_as_str = '''\
POST %s %s
Host: %s
Content-Length: %d
Cookie: csrftoken=%s; sessionid=%s

%s
''' % (path, HTTP_VERSION, HOST, len(data), csrf, session_id, data)
    print '==========================POST Request======================'
    print(request_as_str)
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request_as_str)
        response = recv_response(sock)
        return response

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)



"""
Logging in to fakebook, HTTP POST
1. initial GET request
2. POST with csrf tocken and sessionid
3. get new session id
4. GET with new session id
"""


def login():
    global LOGIN_PATH, HOST, USERNAME, PASSWORD, HOST_PORT, full_login_path, csrf, session_id
    # initial GET request and GET response
    GET_response = http_GET(full_login_path)
    print '---------------------------GET Response---------------------'
    print(GET_response)
    crawl_webpage(GET_response)

    # create POST request to login
    data = 'username=%s&password=%s&csrfmiddlewaretoken=%s&next=%%2Ffakebook%%2F' % (USERNAME, PASSWORD, csrf)
    post_response = http_POST(LOGIN_PATH, data)
    print('-------------------------POST Response---------------------------------')
    print(str(post_response))

    # renew session id
    crawl_webpage(post_response)
    print("new session id = " + str(session_id))
    print("post is not None: " + post_response)
    (POST_status, POST_response) = handle_http_status_codes(post_response, LOGIN_PATH)
    if POST_status == '200':
        crawl_webpage(POST_response)



"""
crawls the webpage: find new links to visit and find flags
"""
def crawl_webpage(response):
    global parser
    parser.feed(response)
    # csrf token and session id should be updated
    print '==========================token and session======================'
    print csrf
    print session_id



"""
TODO chunks:
use one parser for the entire file
check flag length when add to flags_list
if not 64, then chunked = True, add initial part of the next response
in handle_end_tag, if chunked = True

# a list of sites that are visited
# a list of sites to be visited
# only craw the pages that are valid, starts with fring.ccs.neu.edu

# loggin:
    # 
# Request class / Reponse class
# implement HTTP/1.1:
    # contains host in the header
# HTTP requests:
    # GET
    # POST
    # COOKIE MANAGEMENT
# HTTP Response:
    # 301
    # 403
    # 404
    # 500
# Interpret the responded html, and find flgas
"""
def main():
    login()
    # not yet gathered all 5 flags
    while len(paths_tovisit) > 0 and len(secret_flags) < 5:
        # crawl all links found
        for path in list(paths_tovisit):
            # if the current url hasn't been visited yet, then crawl it
            if path not in paths_visited:
                # GET and crawl webpage
                (status_code, response) = http_GET_with_cookie(path)
                if status_code == '200':
                    crawl_webpage(response)
                    # add path to list of path already visited
                    if path not in paths_visited:
                        paths_visited.append(path)
                    # remove path from to visit list of paths
                    if path in paths_tovisit:
                        paths_tovisit.remove(path)


if __name__ == "__main__":
    main()


