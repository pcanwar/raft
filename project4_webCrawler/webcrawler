#!/usr/bin/python

import socket
import sys
from HTMLParser import HTMLParser
from urlparse import urlparse

import time

USERNAME = "1778409"
PASSWORD = "ZUE3UDQE"

fakebook_url = urlparse('http://fring.ccs.neu.edu/fakebook/')
login_url = urlparse('http://fring.ccs.neu.edu/accounts/login/?next=/fakebook/')
full_login_path = "/accounts/login/?next=/fakebook/"
HOST = fakebook_url.netloc 
# fakebook_url.netloc fring.ccs.neu.edu
FAKEBOOK_PATH = fakebook_url.path
LOGIN_PATH = login_url.path
HTTP_VERSION = "HTTP/1.1"

PORT = 80
HOST_PORT = (HOST, PORT)

paths_visited = []
paths_tovisit = []
secret_flags = []

csrf = ''
session_id = ''

# secret_flags_file = open('secret_flags', 'w')

class PageParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.secret_flag_found = False

    def handle_starttag(self, tag, attrs):
        global paths_visited, paths_tovisit, secret_flags
        # find links in the page
        if tag == 'a':
            for attr, val in attrs:
                if attr == 'href':
                    # only add to tovisit list if the url has not been visited
                    # doesn't exist in tovisit list already, and it's valid
                    val_path = urlparse(val).path
                    if val_path not in paths_visited and val_path not in paths_tovisit and val.startswith('/') and val.endswith('/'):
                        print("found: %s" % val_path)
                        paths_tovisit.append(val_path)
                        print("add a new valid url to visit: %s" % val_path)
        # find secret flag
        if tag == 'h2':
            for attr, val in attrs:
                if attr == 'class' and val == 'secret_flag':
                    self.secret_flag_found = True


    def handle_endtag(self, tag):
        global paths_visited, paths_tovisit
        if tag == "html":
            # TODO
            # remove the url from tovisit list
            # if new_url_path in urls_tovisit:
            #     urls_tovisit.remove(new_url_path)
            # if new_url_path not in urls_visited:
            #     urls_visited.append(new_url_path)
            # add to visited list
            #urls_tovisit.remove()
            pass

    def handle_data(self, data):
        global paths_visited, paths_tovisit, secret_flags, csrf, session_id
        #print("Data: " + data)
        if "csrftoken" in data:
            csrf = data.split("csrftoken=")[1].split(";")[0]

        if "sessionid" in data:
            session_id = data.split("sessionid=")[1].split(";")[0]

        if self.secret_flag_found:
            flag = data.split(" ")[1]
            print "!!!!!!!!!!!!!!!!!!!!!!!!!!!!maybe this is the flag: " + str(flag)
            # TODO check flag length
            if flag not in secret_flags:
                secret_flags.append(flag)
                self.secret_flag_found = False
                # print("appended text", file=secret_flags_file)
                with open('secert_flags', 'a') as secret_flags_file:
                    secret_flags_file.write(str(flag) + '\n')

                print "Yay!!! Found one secret flag %s" % str(flag)


parser = PageParser()


"""
receive HTTP responses using the socket
"""
def recv_response(sock, timeout=1/100):

    full_response = ''
    full_response += sock.recv(9000)
    print("in recv_response")
    cur_time = time.time()
    deadline = cur_time + timeout
    while '</html>' not in full_response:
        # socket should time out if it exceeds deadline
        if time.time() > deadline:
            print("break out")
            break
        sock.settimeout(deadline - time.time())
        resp = sock.recv(9000)
        print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~in while, before set timeout\n\n\n\n\n\n\n") # TODO only print this when timeout=1
        if resp:
            print("add rep to full_response")
            full_response += resp

    sock.close()
    return full_response




"""
    handle returned status codes
    200 - accepted
    301 - moved permanently. try the request again using the new URL given by the server in the Location header.
    403 - Forbidden
    404 - Not Found 
     Our web server may return these codes in order to trip up your crawler.
     In this case, your crawler should abandon the URL that generated the error code.
    500 - Internal Server Error
     Our web server may randomly return this error code to your crawler.
     In this case, your crawler should re-try the request for the URL until the request is successful.
"""

def handle_http_status_codes(response, path):
    global paths_visited, paths_tovisit
    print("----------int handle_status_codes: path(%s)----------" % path)

    status_code = response.split(' ')[1]
    if status_code == '200':
         return (status_code, response)

    if status_code == '302':
        new_url = response.split('Location: ')[1].split('\n')[0]
        new_url_path = urlparse(new_url).path
        print("new path from POST: " + str(new_url_path))

        # redirect GET to the new url path
        if session_id == '':
            (new_status_code, new_response) = http_GET(new_url_path)
        else:
            # make get (cookie) request again
            (new_status_code, new_response) = http_GET_with_cookie(new_url_path)
        # remove url path from tovisit, add to visited
        if new_url_path in paths_tovisit:
            paths_tovisit.remove(new_url_path)
        if new_url_path not in paths_visited:
            paths_visited.append(new_url_path)
        print "----------------------new GET response from 302------------------"
        print new_response  # TODO if delete this then no welcome page, why
        return (new_status_code, new_response)

    if status_code == '403' or status_code == '404':
        # abondon url path
        # remove url from tovisit, add to visited
        if path in paths_tovisit:
            paths_tovisit.remove(path)
        if path not in paths_visited:
            paths_visited.append(path)
        return (status_code, response)

    if status_code == '500':
        if session_id == '':
            (new_status_code, new_response) = http_GET(path)
        else:
            # make get (cookie) request again
            (new_status_code, new_response) = http_GET_with_cookie(path)
        return (new_status_code, new_response)


"""
    HTTP GET request
"""
def http_GET(path):
    global HOST_PORT, HOST, HTTP_VERSION
    # construct GET request
    request_as_str = "GET %s %s\nHost: %s\n\n" % (path, HTTP_VERSION, HOST)
    print('==========================GET Request======================')
    print(request_as_str)
    # send GET request
    # create the socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request_as_str)
        # get response
        response = recv_response(sock)
        (status_code, resp) = handle_http_status_codes(response, path)
        return (status_code, resp)

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)


"""
    HTTP GET request with the cookie
"""
def http_GET_with_cookie(path):
    global session_id, csrf, HOST_PORT, HOST, HTTP_VERSION
    print("in http_GET_with_cookie hope path is right*******%s************" % path)
#     request_as_str = '''\
# GET %s %s
# Host: %s
# Cookie: csrftoken=%s; sessionid=%s
#
# ''' % (path, HTTP_VERSION, HOST, csrf, session_id)
    request =  'GET %s %s\n' % (path, HTTP_VERSION)
    request += 'Host: %s\n' % (HOST)
    request += 'Cookie: csrftoken=%s; sessionid=%s\n\n' % (csrf, session_id)
    print(path)
    print '==========================GET Request with cookie======================'
    print(request)
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request)
        #sock.settimeout(None) # TODO should i set timeout here?
        response = recv_response(sock)
        (status_code, resp) = handle_http_status_codes(response, path)
        return (status_code, resp)

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)


"""
    HTTP POST request
"""
def http_POST(path, data):
    global HOST_PORT, HTTP_VERSION, HOST, session_id, csrf
    request_as_str = '''\
POST %s %s
Host: %s
Content-Length: %d
Cookie: csrftoken=%s; sessionid=%s

%s
''' % (path, HTTP_VERSION, HOST, len(data), csrf, session_id, data)
    print '==========================POST Request======================'
    print(request_as_str)
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # connect to the socket
        sock.connect(HOST_PORT)
        sock.sendall(request_as_str)
        response = recv_response(sock)
        return response

    except socket.error as e:
        print 'ERROR: Failed to create socket! %s' %e
        exit(1)



"""
Logging in to fakebook, HTTP POST
1. initial GET request
2. POST with csrf tocken and sessionid
3. get new session id
4. GET with new session id
"""


def login():
    global LOGIN_PATH, HOST, USERNAME, PASSWORD, HOST_PORT, full_login_path, csrf, session_id
    # initial GET request and GET response
    (GET_status, GET_response) = http_GET(full_login_path)
    print '---------------------------GET Response---------------------'
    print(GET_response)
    if GET_status == '200':
        crawl_webpage(GET_response)
    else:
        print"First GET failed, exit the program"
        sys.exit(1)

    # create POST request to login
    data = 'username=%s&password=%s&csrfmiddlewaretoken=%s&next=%%2Ffakebook%%2F' % (USERNAME, PASSWORD, csrf)
    post_response = http_POST(LOGIN_PATH, data)
    print('-------------------------POST Response---------------------------------')
    print(str(post_response))

    # renew session id
    crawl_webpage(post_response)
    print("new session id = " + str(session_id))
    (POST_status, POST_response) = handle_http_status_codes(post_response, LOGIN_PATH)
    print(POST_status)
    if POST_status == '200':
        print('-------------------------POST_response: before crawl the first welcome page---------------------------------')
        print(POST_response)
        crawl_webpage(POST_response)



"""
crawls the webpage: find new links to visit and find flags
"""
def crawl_webpage(response):
    global parser
    parser.feed(response)
    # csrf token and session id should be updated
    print '==========================token and session======================'
    print csrf
    print session_id



"""
TODO chunks:
use one parser for the entire file
check flag length when add to flags_list
if not 64, then chunked = True, add initial part of the next response
in handle_end_tag, if chunked = True

# a list of sites that are visited
# a list of sites to be visited
# only craw the pages that are valid, starts with fring.ccs.neu.edu

# loggin:
    # 
# Request class / Reponse class
# implement HTTP/1.1:
    # contains host in the header
# HTTP requests:
    # GET
    # POST
    # COOKIE MANAGEMENT
# HTTP Response:
    # 301
    # 403
    # 404
    # 500
# Interpret the responded html, and find flgas
"""
def main():
    login()

    print("about the crawl all: paths_tovisit: %d" % len(paths_tovisit))
    # not yet gathered all 5 flags
    # while len(paths_tovisit) > 0 and len(secret_flags) < 5:
    #     print("len(paths_tovisit) = %d" % len(paths_tovisit))
    #     print("len(secret_flags) = %d" % len(secret_flags))
    #     # crawl all links found
    #     for path in list(paths_tovisit):
    #         # if the current url hasn't been visited yet, then crawl it
    #         if path not in paths_visited:
    #             # GET and crawl webpage
    #             (status_code, response) = http_GET_with_cookie(path)
    #             if status_code == '200':
    #                 crawl_webpage(response)
    #                 # add path to list of path already visited
    #                 if path not in paths_visited:
    #                     paths_visited.append(path)
    #                 # remove path from to visit list of paths
    #                 if path in paths_tovisit:
    #                     paths_tovisit.remove(path)



if __name__ == "__main__":
    main()


